op0: SchedulerNode(ComputedBuffer)
op0.writes = [MemoryDep('buf0', c0, {c0: 524288}, None)]
op0.unmet_dependencies = []
op0.met_dependencies = 
    [   MemoryDep('arg1_1', c0, {c0: 2048}, None),
        MemoryDep('arg2_1', c0, {c0: 524288}, None)]
op0.outputs = [
    buf0: ComputedBuffer
    buf0.layout = FixedLayout('cuda', torch.bfloat16, size=[2048, 256], stride=[256, 1])
    buf0.users = [NodeUser(node=ExternKernelSchedulerNode(name='op1'), can_inplace=False, is_weak=False)]
]
op0.group.device = cuda:0
op0.group.iteration = (524288, 1)
op0.sizes = ([2048, 256], [])
arg2_1_layout = FixedLayout('cuda', torch.bfloat16, size=[2048, 256], stride=[256, 1])
arg1_1_layout = FixedLayout('cuda', torch.bfloat16, size=[2048], stride=[1])
buf0_layout = FixedLayout('cuda', torch.bfloat16, size=[2048, 256], stride=[256, 1])
class op0_loop_body:
    var_ranges = {z0: 2048, z1: 256}
    index0 = 256*z0 + z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('arg2_1', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg1_1', get_index_1)
        mul = ops.mul(load, load_1)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf0', get_index_2, mul, None)
        return store
op0 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[524288], 
        filename=__file__,
        triton_meta={'signature': {0: '*bf16', 1: '*bf16', 2: '*bf16', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=108), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '54E46422D5DB2E55B804C8E038A4A0E2ECEED6FCC5402DED453936C14F5DFA13', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 524288
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = tl.full([XBLOCK], True, tl.int1)
        x2 = xindex
        x1 = (xindex // 256)
        tmp0 = tl.load(in_ptr0 + (x2), None).to(tl.float32)
        tmp1 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last').to(tl.float32)
        tmp2 = tmp0 * tmp1
        tl.store(out_ptr0 + (x2), tmp2, None)


op1: ExternKernelSchedulerNode(ExternKernelOut)
op1.writes = [StarDep(name='buf1', mode=None)]
op1.unmet_dependencies = [StarDep(name='buf0', mode=None)]
op1.met_dependencies = [StarDep(name='arg0_1', mode=None)]
op1.outputs = [
    buf1: ExternKernelOut
    buf1.layout = FixedLayout('cuda', torch.bfloat16, size=[128, 256], stride=[256, 1])
    buf1.users = [NodeUser(node=SchedulerNode(name='op2'), can_inplace=True, is_weak=False)]
]
op1.node.kernel = extern_kernels.mm


op2: SchedulerNode(ComputedBuffer)
op2.writes = [MemoryDep('buf2', c0, {c0: 32768}, None)]
op2.unmet_dependencies = [MemoryDep('buf1', c0, {c0: 32768}, None)]
op2.met_dependencies = 
    [   MemoryDep('arg3_1', c0, {c0: 128}, None),
        MemoryDep('arg4_1', c1, {c0: 128, c1: 256}, None)]
op2.outputs = [
    buf2: ComputedBuffer
    buf2.layout = FixedLayout('cuda', torch.bfloat16, size=[128, 256], stride=[256, 1])
    buf2.users = [
        NodeUser(node=ExternKernelSchedulerNode(name='op3'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op2.group.device = cuda:0
op2.group.iteration = (32768, 1)
op2.sizes = ([128, 256], [])
arg3_1_layout = FixedLayout('cuda', torch.bfloat16, size=[128], stride=[1])
arg4_1_layout = FixedLayout('cuda', torch.bfloat16, size=[256], stride=[1])
buf1_layout = FixedLayout('cuda', torch.bfloat16, size=[128, 256], stride=[256, 1])
buf2_layout = FixedLayout('cuda', torch.bfloat16, size=[128, 256], stride=[256, 1])
class op2_loop_body:
    var_ranges = {z0: 128, z1: 256}
    index0 = z0
    index1 = z1
    index2 = 256*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('arg3_1', get_index)
        neg = ops.neg(load)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg4_1', get_index_1)
        mul = ops.mul(neg, load_1)
        exp = ops.exp(mul)
        get_index_2 = self.get_index('index2')
        load_2 = ops.load('buf1', get_index_2)
        mul_1 = ops.mul(exp, load_2)
        get_index_3 = self.get_index('index2')
        store = ops.store('buf2', get_index_3, mul_1, None)
        return store
op2 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[32768], 
        filename=__file__,
        triton_meta={'signature': {0: '*bf16', 1: '*bf16', 2: '*bf16', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=108), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': '54E46422D5DB2E55B804C8E038A4A0E2ECEED6FCC5402DED453936C14F5DFA13', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 32768
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = tl.full([XBLOCK], True, tl.int1)
        x1 = (xindex // 256)
        x0 = xindex % 256
        x2 = xindex
        tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last').to(tl.float32)
        tmp2 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last').to(tl.float32)
        tmp5 = tl.load(in_out_ptr0 + (x2), None).to(tl.float32)
        tmp1 = -tmp0
        tmp3 = tmp1 * tmp2
        tmp4 = tl_math.exp(tmp3)
        tmp6 = tmp4 * tmp5
        tl.store(in_out_ptr0 + (x2), tmp6, None)


op3: ExternKernelSchedulerNode(ExternKernelOut)
op3.writes = [StarDep(name='buf3', mode=None)]
op3.unmet_dependencies = [StarDep(name='buf2', mode=None)]
op3.met_dependencies = [StarDep(name='arg0_1', mode=None)]
op3.outputs = [
    buf3: ExternKernelOut
    buf3.layout = FixedLayout('cuda', torch.bfloat16, size=[2048, 256], stride=[256, 1])
    buf3.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op3.node.kernel = extern_kernels.mm


